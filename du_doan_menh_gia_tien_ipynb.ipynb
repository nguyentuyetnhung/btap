{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyentuyetnhung/btap/blob/main/du_doan_menh_gia_tien_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "zx9VdGpUn8u4",
        "outputId": "a9fe589b-8fa3-42ee-8ee3-97ac83430d01"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ ƒê√£ t√¨m th·∫•y m√¥ h√¨nh ƒë√£ train, ƒëang t·∫£i...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ƒê√£ t·∫£i labels t·ª´ file\n",
            "‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh ƒë√£ train th√†nh c√¥ng!\n",
            "üöÄ ƒêang kh·ªüi ch·∫°y ·ª©ng d·ª•ng...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5f32ecc44b1802c3ee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5f32ecc44b1802c3ee.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, InputLayer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import gradio as gr\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# ================== 1. K·∫æT N·ªêI GOOGLE DRIVE ==================\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Th∆∞ m·ª•c ch·ª©a dataset trong Drive\n",
        "base_dir = \"/content/drive/MyDrive/codetien\"\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n l∆∞u m√¥ h√¨nh\n",
        "model_dir = \"/content/drive/MyDrive/dudoangiatien\"\n",
        "os.makedirs(model_dir, exist_ok=True)  # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\n",
        "\n",
        "best_model_path = os.path.join(model_dir, \"best_model.h5\")\n",
        "final_model_path = os.path.join(model_dir, \"doangiatien.h5\")\n",
        "history_plot_path = os.path.join(model_dir, \"training_history.png\")\n",
        "labels_path = os.path.join(model_dir, \"class_labels.npy\")\n",
        "\n",
        "# ================== 2. KI·ªÇM TRA XEM M√î H√åNH ƒê√É ƒê∆Ø·ª¢C TRAIN CH∆ØA ==================\n",
        "def load_trained_model():\n",
        "    \"\"\"Ki·ªÉm tra v√† t·∫£i m√¥ h√¨nh ƒë√£ train n·∫øu c√≥\"\"\"\n",
        "    if os.path.exists(best_model_path) and os.path.exists(labels_path):\n",
        "        print(\"‚úÖ ƒê√£ t√¨m th·∫•y m√¥ h√¨nh ƒë√£ train, ƒëang t·∫£i...\")\n",
        "        model = load_model(best_model_path)\n",
        "\n",
        "        # T·∫£i labels t·ª´ file\n",
        "        class_indices = np.load(labels_path, allow_pickle=True).item()\n",
        "        labels = {v: k for k, v in class_indices.items()}\n",
        "        print(\"‚úÖ ƒê√£ t·∫£i labels t·ª´ file\")\n",
        "        return model, labels, class_indices\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ƒë√£ train ho·∫∑c file labels, c·∫ßn train m·ªõi\")\n",
        "        return None, None, None\n",
        "\n",
        "# Th·ª≠ t·∫£i m√¥ h√¨nh ƒë√£ train\n",
        "model, labels, class_indices = load_trained_model()\n",
        "\n",
        "# N·∫øu ch∆∞a c√≥ m√¥ h√¨nh, ti·∫øn h√†nh train\n",
        "if model is None:\n",
        "    # ================== 3. TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ==================\n",
        "    img_size = (150, 150)\n",
        "    batch_size = 32\n",
        "\n",
        "    print(\"Ki·ªÉm tra c·∫•u tr√∫c th∆∞ m·ª•c:\")\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        level = root.replace(base_dir, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:3]:\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"{subindent}... v√† {len(files) - 3} file kh√°c\")\n",
        "\n",
        "    # TƒÉng c∆∞·ªùng d·ªØ li·ªáu m·∫°nh h∆°n\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.3,\n",
        "        shear_range=0.2,\n",
        "        brightness_range=[0.7, 1.3],\n",
        "        fill_mode='nearest',\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=True,\n",
        "        subset=\"training\"\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        base_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        shuffle=False,\n",
        "        subset=\"validation\"\n",
        "    )\n",
        "\n",
        "    # L∆∞u class indices ƒë·ªÉ s·ª≠ d·ª•ng sau\n",
        "    class_indices = train_generator.class_indices\n",
        "    np.save(labels_path, class_indices)\n",
        "    labels = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "    # Ki·ªÉm tra s·ªë l∆∞·ª£ng ·∫£nh trong m·ªói l·ªõp training\n",
        "    class_counts = {}\n",
        "    for class_name, idx in class_indices.items():\n",
        "        count = np.sum(train_generator.classes == idx)\n",
        "        class_counts[class_name] = count\n",
        "        print(f\"L·ªõp {class_name}: {count} ·∫£nh\")\n",
        "\n",
        "    # Ki·ªÉm tra c√¢n b·∫±ng d·ªØ li·ªáu\n",
        "    min_count = min(class_counts.values())\n",
        "    max_count = max(class_counts.values())\n",
        "    if max_count > 1.5 * min_count:\n",
        "        print(\"\\n‚ö†Ô∏è C·∫£nh b√°o: D·ªØ li·ªáu kh√¥ng c√¢n b·∫±ng! C√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng m√¥ h√¨nh.\")\n",
        "\n",
        "    # ================== 4. X√ÇY D·ª∞NG M√î H√åNH ANN ==================\n",
        "    model = Sequential([\n",
        "        InputLayer(input_shape=(img_size[0], img_size[1], 3)), # Explicitly define input shape\n",
        "        Flatten(),\n",
        "        Dense(2048, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.6),\n",
        "        Dense(1024, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(512, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(len(class_indices), activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # ================== 5. COMPILE ==================\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=7, min_lr=0.00001)\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        best_model_path,\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ================== 6. TRAIN ==================\n",
        "    print(\"B·∫Øt ƒë·∫ßu training...\")\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=max(1, train_generator.samples // batch_size),\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=max(1, val_generator.samples // batch_size),\n",
        "        epochs=100,\n",
        "        callbacks=[early_stopping, reduce_lr, checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ================== 7. L∆ØU M√î H√åNH CU·ªêI C√ôNG ==================\n",
        "    model.save(final_model_path)\n",
        "    print(f\"‚úÖ ƒê√£ train xong v√† l∆∞u m√¥ h√¨nh ANN t·∫°i: {final_model_path}\")\n",
        "\n",
        "    # V·∫Ω bi·ªÉu ƒë·ªì accuracy v√† loss\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(history_plot_path)\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh ƒë√£ train th√†nh c√¥ng!\")\n",
        "    # Get img_size from model input shape\n",
        "    img_size = model.input_shape[1:3]  # Assuming the input layer is the first layer\n",
        "\n",
        "# ================== 8. T·∫†O GIAO DI·ªÜN GRADIO ==================\n",
        "# H√†m x·ª≠ l√Ω ·∫£nh\n",
        "def preprocess_image(img):\n",
        "    # Chuy·ªÉn ƒë·ªïi sang RGB n·∫øu l√† ·∫£nh RGBA\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize v√† chu·∫©n h√≥a\n",
        "    img_resized = img.resize(img_size)\n",
        "    img_array = img_to_array(img_resized) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array, img_resized\n",
        "\n",
        "# H√†m d·ª± ƒëo√°n\n",
        "def predict_and_show(img):\n",
        "    if img is None:\n",
        "        return \"Vui l√≤ng t·∫£i l√™n m·ªôt ·∫£nh h·ª£p l·ªá\", None\n",
        "\n",
        "    try:\n",
        "        img_array, processed_img = preprocess_image(img)\n",
        "\n",
        "        # D·ª± ƒëo√°n\n",
        "        preds = model.predict(img_array, verbose=0)\n",
        "\n",
        "        # Ensure preds is an array of probabilities\n",
        "        if preds.shape == (1,):\n",
        "          preds = np.array([preds]) # Reshape to (1, 1) if it's a single value\n",
        "\n",
        "        class_idx = np.argmax(preds[0])\n",
        "        confidence = np.max(preds[0])\n",
        "        label = labels[class_idx]\n",
        "\n",
        "        # T·∫°o bi·ªÉu ƒë·ªì x√°c su·∫•t\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "        # Hi·ªÉn th·ªã ·∫£nh\n",
        "        ax1.imshow(processed_img)\n",
        "        ax1.set_title('·∫¢nh ƒë√£ t·∫£i l√™n')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì x√°c su·∫•t\n",
        "        classes = list(labels.values())\n",
        "        probabilities = preds[0]\n",
        "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "        bars = ax2.bar(classes, probabilities, color=colors)\n",
        "        ax2.set_ylabel('X√°c su·∫•t')\n",
        "        ax2.set_title('X√°c su·∫•t d·ª± ƒëo√°n')\n",
        "        ax2.set_ylim(0, 1)\n",
        "\n",
        "        # Th√™m gi√° tr·ªã tr√™n m·ªói c·ªôt\n",
        "        for bar, prob in zip(bars, probabilities):\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{prob:.2%}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        result_text = f\"üíµ M·ªánh gi√°: {label} ngh√¨n ƒë·ªìng\\nüéØ ƒê·ªô tin c·∫≠y: {confidence*100:.2f}%\"\n",
        "        return result_text, fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"L·ªói x·ª≠ l√Ω ·∫£nh: {str(e)}\", None\n",
        "\n",
        "# CSS t√πy ch·ªânh\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "    max-width: 1200px !important;\n",
        "    margin: 20px auto;\n",
        "    border-radius: 20px;\n",
        "    box-shadow: 0 15px 35px rgba(0,0,0,0.2);\n",
        "    padding: 30px;\n",
        "}\n",
        "h1 {\n",
        "    text-align: center;\n",
        "    color: white;\n",
        "    font-weight: 700;\n",
        "    margin-bottom: 10px;\n",
        "    font-size: 2.5em;\n",
        "    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
        "}\n",
        "h2 {\n",
        "    text-align: center;\n",
        "    color: #f8f9fa;\n",
        "    font-weight: 400;\n",
        "    margin-top: 0;\n",
        "    font-size: 1.3em;\n",
        "}\n",
        ".upload-box {\n",
        "    border: 3px dashed #a991f7 !important;\n",
        "    border-radius: 15px;\n",
        "    padding: 25px;\n",
        "    background-color: rgba(255, 255, 255, 0.1);\n",
        "    backdrop-filter: blur(10px);\n",
        "    min-height: 250px;\n",
        "}\n",
        ".upload-box:hover {\n",
        "    border-color: #8a6df0 !important;\n",
        "    background-color: rgba(255, 255, 255, 0.15);\n",
        "}\n",
        "button {\n",
        "    background: linear-gradient(to right, #ff6b6b, #ff8e8e) !important;\n",
        "    color: white !important;\n",
        "    font-weight: bold;\n",
        "    border-radius: 25px !important;\n",
        "    padding: 15px 35px !important;\n",
        "    border: none !important;\n",
        "    box-shadow: 0 5px 15px rgba(255, 107, 107, 0.4);\n",
        "    transition: all 0.3s ease !important;\n",
        "    margin: 20px auto;\n",
        "    display: block;\n",
        "    font-size: 1.1em;\n",
        "}\n",
        "button:hover {\n",
        "    transform: translateY(-3px);\n",
        "    box-shadow: 0 8px 20px rgba(255, 107, 107, 0.6);\n",
        "}\n",
        ".output-textbox textarea {\n",
        "    font-size: 22px !important;\n",
        "    font-weight: bold !important;\n",
        "    color: #2c3e50 !important;\n",
        "    background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;\n",
        "    border-radius: 15px;\n",
        "    padding: 25px !important;\n",
        "    border: 2px solid #e0e0e0 !important;\n",
        "    text-align: center;\n",
        "    box-shadow: 0 5px 15px rgba(0,0,0,0.1);\n",
        "}\n",
        ".footer {\n",
        "    text-align: center;\n",
        "    margin-top: 30px;\n",
        "    color: rgba(255, 255, 255, 0.8);\n",
        "    font-size: 16px;\n",
        "    padding: 20px;\n",
        "    background-color: rgba(0, 0, 0, 0.2);\n",
        "    border-radius: 15px;\n",
        "    backdrop-filter: blur(5px);\n",
        "}\n",
        ".thumbnail {\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    gap: 20px;\n",
        "    margin: 25px 0;\n",
        "}\n",
        ".thumbnail img {\n",
        "    width: 100px;\n",
        "    height: 50px;\n",
        "    border-radius: 8px;\n",
        "    border: 3px solid #a991f7;\n",
        "    padding: 5px;\n",
        "    background: white;\n",
        "    box-shadow: 0 4px 8px rgba(0,0,0,0.2);\n",
        "    transition: transform 0.3s ease;\n",
        "}\n",
        ".thumbnail img:hover {\n",
        "    transform: scale(1.1);\n",
        "}\n",
        ".instructions {\n",
        "    background: rgba(255, 255, 255, 0.1);\n",
        "    padding: 15px;\n",
        "    border-radius: 10px;\n",
        "    margin: 15px 0;\n",
        "    color: white;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# T·∫°o giao di·ªán\n",
        "with gr.Blocks(css=custom_css, title=\"Nh·∫≠n Di·ªán M·ªánh Gi√° Ti·ªÅn\") as demo:\n",
        "    gr.Markdown(\"# üíµ ·ª®NG D·ª®NG NH·∫¨N DI·ªÜN M·ªÜNH GI√Å TI·ªÄN\")\n",
        "    gr.Markdown(\"### T·∫£i l√™n ·∫£nh t·ªù ti·ªÅn 100, 200 ho·∫∑c 500 ngh√¨n ƒë·ªìng ƒë·ªÉ nh·∫≠n di·ªán\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div class=\"instructions\">\n",
        "    <strong>üìù H∆∞·ªõng d·∫´n:</strong><br>\n",
        "    1. Ch·ªçn ·∫£nh t·ªù ti·ªÅn c·∫ßn nh·∫≠n di·ªán (100k, 200k ho·∫∑c 500k)<br>\n",
        "    2. Nh·∫•n n√∫t \"üîç Nh·∫≠n di·ªán m·ªánh gi√°\" ƒë·ªÉ ph√¢n t√≠ch<br>\n",
        "    3. Xem k·∫øt qu·∫£ v√† bi·ªÉu ƒë·ªì x√°c su·∫•t d·ª± ƒëo√°n\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            <div class=\"thumbnail\">\n",
        "                <img src=\"https://static.vecteezy.com/system/resources/previews/024/761/402/non_2x/cash-100000-vnd-banknote-close-up-of-vietnamese-money-isolated-on-white-background-vector.jpg\" alt=\"100k\">\n",
        "                <img src=\"https://static.vecteezy.com/system/resources/previews/024/761/406/non_2x/cash-200000-vnd-banknote-close-up-of-vietnamese-money-isolated-on-white-background-vector.jpg\" alt=\"200k\">\n",
        "                <img src=\"https://static.vecteezy.com/system/resources/previews/024/761/407/non_2x/cash-500000-vnd-banknote-close-up-of-vietnamese-money-isolated-on-white-background-vector.jpg\" alt=\"500k\">\n",
        "            </div>\n",
        "            \"\"\",\n",
        "            elem_id=\"thumbnail\"\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            img_input = gr.Image(type=\"pil\", label=\"üì∑ T·∫£i l√™n ·∫£nh t·ªù ti·ªÅn\", elem_classes=\"upload-box\", height=300)\n",
        "            submit_btn = gr.Button(\"üîç Nh·∫≠n di·ªán m·ªánh gi√°\", size=\"lg\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            output_text = gr.Textbox(label=\"üìå K·∫øt qu·∫£ nh·∫≠n di·ªán\", interactive=False, lines=3)\n",
        "            plot_output = gr.Plot(label=\"üìä Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n\")\n",
        "\n",
        "    submit_btn.click(fn=predict_and_show, inputs=img_input, outputs=[output_text, plot_output])\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <div class=\"footer\">\n",
        "        <strong>·ª®ng d·ª•ng nh·∫≠n di·ªán m·ªánh gi√° ti·ªÅn Vi·ªát Nam</strong><br>\n",
        "        S·ª≠ d·ª•ng m√¥ h√¨nh Artificial Neural Network (ANN) ƒë·ªÉ ph√¢n t√≠ch v√† nh·∫≠n di·ªán<br>\n",
        "        H·ªó tr·ª£ c√°c m·ªánh gi√°: 100, 200 v√† 500 ngh√¨n ƒë·ªìng\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        elem_id=\"footer\"\n",
        "    )\n",
        "\n",
        "print(\"üöÄ ƒêang kh·ªüi ch·∫°y ·ª©ng d·ª•ng...\")\n",
        "demo.launch(debug=True, share=True, height=800)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nB85gUJSVrD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbDuE4Xf7hK6WN1z4DkNyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}